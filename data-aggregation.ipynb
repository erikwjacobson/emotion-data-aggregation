{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aggregation for the \"Interpreting Emotion in Messages\" Study\n",
    "\n",
    "* Project and code written by Erik Jacobson\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data from an API\n",
    "\n",
    "* The data is stored in a SQL database through the cloud, and can be accessed using an API.\n",
    "\n",
    "* The API is only accessible if you have a key, which itself can only be obtained through administrator accounts.\n",
    "\n",
    "To access the data, I need to make a request to the API endpoint and store the returned JSON data in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded User data from https://emotion.ewjresearch.com/\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Getting the Data\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# The data can be accessed through an API\n",
    "studySite = \"https://emotion.ewjresearch.com/\"\n",
    "apiKey = open(\"APIKey.txt\", \"r\").read()\n",
    "\n",
    "headers = {'Authorization' : apiKey, 'Accept': 'application/json'}\n",
    "\n",
    "# Make the request to get the users resource\n",
    "response = requests.get(studySite + \"api/users\", headers=headers)\n",
    "\n",
    "if(response.status_code != 200): # If not successful\n",
    "    print(response.status_code)\n",
    "    print(response.text)\n",
    "    print('The server didn\\'t respond. Using backup JSON data for now.')\n",
    "    print('Get a new key to access the new data.')\n",
    "else: # If successful\n",
    "    # Write the JSON to a data file\n",
    "    with open(\"UserJson.json\", \"w\") as dataFile:\n",
    "        # Get what's inside of data array\n",
    "        data = json.loads(response.text)['data']\n",
    "        dataFile.write(json.dumps(data))\n",
    "        dataFile.close()\n",
    "    print(\"Successfully downloaded User data from \" + studySite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the JSON data is written to a file which we'll call `UserJson.json`. This way, I can manipulate the raw data without having to request the server each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "    \n",
    "## Creating a Users Dataframe\n",
    "\n",
    "- The data is formatted in JSON with users containing an array `records` containing individual objects that represent each of the questions on the app.\n",
    "\n",
    "- Each user object should be represented as a row in the excel output, with attributes (such as `username`) represented as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Loading the data from the JSON\n",
    "#\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "# Setup for excel writing\n",
    "excel = pd.ExcelWriter('output.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Getting the initial user information\n",
    "data = json.loads(open(\"UserJson.json\", \"r\").read())\n",
    "columns =([\n",
    "    'id',\n",
    "    'username',\n",
    "    'computer',\n",
    "    'researcher',\n",
    "    'admin',\n",
    "    'overtime',\n",
    "    'credit_granted',\n",
    "    'progress',\n",
    "    'age',\n",
    "    'primary_language',\n",
    "    'facebook_use',\n",
    "    'instagram_use',\n",
    "    'twitter_use',\n",
    "    'youtube_use',\n",
    "    'comments',\n",
    "])\n",
    "\n",
    "# Pandas can automatically convert JSON into a dataframe.\n",
    "users = (pd.DataFrame(data, columns=columns)\n",
    "           .rename(index=str, columns={\"id\": \"user_id\"}))\n",
    "\n",
    "# Export Just Users to Excel\n",
    "users.to_excel(excel, sheet_name='Users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformatting user's answers to questions\n",
    "\n",
    "Now that we have all of the users in their own excel sheet, I need to generate two sheets that contain columns for every question on the application, with one sheet's values indicating whether or not they answered the question correctly, and the other sheet's values indicating the answer they actually gave. This requires a bit of reformatting due to the structure of the JSON response...\n",
    "\n",
    "The JSON object looks a bit similar to this:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"username\": \"erik\",\n",
    "        \"records\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"correct\": true,\n",
    "                \"sentence\": [\n",
    "                    {\n",
    "                        \"text\": \"wat do u mean\"   \n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "I've only included the data I need in the above JSON example, since this sheet in the document will contain one column for each `record`, with the sentence text as the column header and the correct attribute for the value in that column. In order to do this, I need to accomplish a few things:\n",
    "    \n",
    "    1. I need to filter out all of the users that didn't finish each sentence\n",
    "    2. I need to gather the records for each user in a dataframe \n",
    "    3. I need to pivot those records so that the sentence text value is the column header and the values are the correctness\n",
    "    4. I need to append the pivoted records to the end of each user row so that each row contains each question and the intended value.\n",
    "    5. I need to reorder the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final DF to be exported to excel\n",
    "finalCorrect = pd.DataFrame()\n",
    "finalAnswer = pd.DataFrame()\n",
    "\n",
    "# Define the necessary columns\n",
    "recordColumns = ([\n",
    "    'user_id',\n",
    "    'answer',\n",
    "    'correct',\n",
    "    'sentence.text'\n",
    "])\n",
    "\n",
    "# For each user\n",
    "#   Step 2. Gather the records\n",
    "#   Step 3. Pivot the dataframe so that the columns become individual sentence text and the user's answers become the row\n",
    "#   Step 4. Join the pivoted dataframe to the old users dataframe\n",
    "for user in data:\n",
    "    # (Step 1) Skip all users that haven't completed every question\n",
    "    if(user['progress'] != 100):\n",
    "        continue\n",
    "        \n",
    "    # (Step 2) Gather records in wanted format\n",
    "    records = json_normalize(user['records']) \n",
    "    recordsFrame = pd.DataFrame(records, columns=recordColumns)\n",
    "    \n",
    "    # Change correct (boolean type) to integer\n",
    "    recordsFrame['correct'] = recordsFrame['correct'].astype(int)\n",
    "    \n",
    "    # (Step 3) Pivot to create a column for each sentence\n",
    "    recordsCorrectFrame = recordsFrame.pivot(index='user_id', columns='sentence.text', values='correct')\n",
    "    recordsAnswerFrame = recordsFrame.pivot(index='user_id', columns='sentence.text', values='answer')\n",
    "    \n",
    "    # (Step 4) Append recordsFrame to the final product\n",
    "    finalCorrect = finalCorrect.append(users.merge(recordsCorrectFrame, on='user_id'), sort=True)\n",
    "    finalAnswer = finalAnswer.append(users.merge(recordsAnswerFrame, on='user_id'), sort=True)\n",
    "\n",
    "\n",
    "# (Step 5) Reorder columns\n",
    "updatedColumns = list(users.columns.values)\n",
    "updatedColumns.extend(list(recordsAnswerFrame.columns.values))\n",
    "\n",
    "finalCorrect = finalCorrect.reindex(columns=updatedColumns)\n",
    "finalAnswer = finalAnswer.reindex(columns=updatedColumns)\n",
    "\n",
    "# Export to excel\n",
    "finalCorrect.to_excel(excel, sheet_name='Sentence_Correct')\n",
    "finalAnswer.to_excel(excel, sheet_name='Sentence_Answer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate averages based on categories\n",
    "\n",
    "Each of the questions are in one of nine categories:\n",
    "\n",
    "| Style/Emotion | Positive | Neutral | Negative |\n",
    "| --- | --- | --- | --- |\n",
    "| **Abbreviation** | `Abbr_Pos` | `Abbr_Neu` | `Abbr_Neg` |\n",
    "| **Grammatical** | `Gramm_Pos` | `Gramm_Neu` | `Gramm_Neg` |\n",
    "| **Emoji** | `Emoji_Pos` | `Emoji_Neu` | `Emoji_Neg` |\n",
    "\n",
    "In order to determine whether or not our hypothesis is supported, we need to know the average number of sentences the participants guessed correctly for each category. To do that, I went back to the original DataFrame and did the following steps:\n",
    "\n",
    "1. I gathered all of the records and the necessary column names for each user\n",
    "2. I generated all 9 averages for each user and appended those to the averages dataframe\n",
    "    - To do this, I queried all of the user records based on style and emotion for each combination \n",
    "3. I filtered to only include people who completed the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully exported excel file.\n"
     ]
    }
   ],
   "source": [
    "recordColumns = ([\n",
    "    'correct',\n",
    "    'sentence.style.id',\n",
    "    'sentence.style.name',\n",
    "    'sentence.emotion.id',\n",
    "    'sentence.emotion.name'\n",
    "])\n",
    "\n",
    "##\n",
    "# Gather means for record scores\n",
    "# - Used as a lookup table\n",
    "newColumns = ({\n",
    "    'Abbr_Pos': [\"Abbreviation\", \"Positive\"],\n",
    "    'Abbr_Neu': [\"Abbreviation\", \"Neutral\"], \n",
    "    'Abbr_Neg': [\"Abbreviation\", \"Negative\"],\n",
    "\n",
    "    'Gramm_Pos': [\"Grammatical\", \"Positive\"],\n",
    "    'Gramm_Neu': [\"Grammatical\", \"Neutral\"], \n",
    "    'Gramm_Neg': [\"Grammatical\", \"Negative\"],\n",
    "\n",
    "    'Emoji_Pos': [\"Emoji\", \"Positive\"],\n",
    "    'Emoji_Neu': [\"Emoji\", \"Neutral\"], \n",
    "    'Emoji_Neg': [\"Emoji\", \"Negative\"]\n",
    "})\n",
    "\n",
    "averages = pd.DataFrame()\n",
    "\n",
    "for user in data:\n",
    "    records = json_normalize(user['records']) # Acquire records    \n",
    "    \n",
    "    # Create a data frame with needed columns\n",
    "    recordsFrame = pd.DataFrame(records, columns=recordColumns)\n",
    "\n",
    "    # Casting for later where clauses\n",
    "    recordsFrame['sentence.style.name'] = recordsFrame['sentence.style.name'].astype(str)\n",
    "    recordsFrame['sentence.emotion.name'] = recordsFrame['sentence.emotion.name'].astype(str)\n",
    "    \n",
    "    dic = {'user_id': user['id']}\n",
    "    for newCol in newColumns:\n",
    "        # Specify conditions with which to filter the records\n",
    "        style = newColumns[newCol][0]\n",
    "        emotion = newColumns[newCol][1]\n",
    "        conditions = (\n",
    "            # where sentence.style.name=\"Style\"\n",
    "            (recordsFrame['sentence.style.name']==style) \n",
    "            \n",
    "            & # AND\n",
    "        \n",
    "            # where sentence.emotion.name=\"Emotion\"\n",
    "            (recordsFrame['sentence.emotion.name']==emotion)\n",
    "        )\n",
    "        \n",
    "        # Filter based on conditions above\n",
    "        temp = recordsFrame[conditions]\n",
    "        \n",
    "        # Obtain the mean of the two selections\n",
    "        mean = temp['correct'].mean()\n",
    "        \n",
    "        # Add that mean to the dictionary of means containing users and \n",
    "        dic.update({newCol: mean})\n",
    "    \n",
    "    # Once the dictionary contains all 9 averages, append it to the dataframe\n",
    "    averages = averages.append(users.merge(pd.DataFrame(dic, index=[0]), on='user_id'))\n",
    "    \n",
    "# Remove items where participant did not finish each question\n",
    "finalAverages = averages[averages.progress==100]\n",
    "\n",
    "# Export\n",
    "finalAverages.to_excel(excel, sheet_name='Category_Averages')\n",
    "excel.save()\n",
    "\n",
    "# Success\n",
    "print(\"Successfully exported excel file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
